import tensorflow as tf
from tensorflow.keras import backend as K


@tf.function
def mean_squared_error(y_true, query, doc):
    """å‡æ–¹å·®æ ¸å¿ƒå‡½æ•°
    """
    y_pred = tf.reduce_sum(query * doc, axis=1)
    return tf.reduce_mean((y_true - y_pred) ** 2)


@tf.function
def binary_cross_entropy(y_true, query, doc):
    """äº¤å‰ç†µæ ¸å¿ƒå‡½æ•°
    """
    y_pred = tf.reduce_sum(query * doc, axis=1)
    return K.binary_crossentropy(y_true, y_pred)


@tf.function
def cosent_loss(y_true, y_pred, scale=20):
    """cosent æ ¸å¿ƒå‡½æ•°
    """
    y_true = K.cast(y_true[:, None] < y_true[None, :], K.floatx())  # query-docå¯¹ label ä¸¤ä¸¤æ¯”è¾ƒï¼Œy_true[i, j]ä»£è¡¨ ç¬¬iå¯¹label æ˜¯å¦å°äº ç¬¬jå¯¹label
    y_pred = y_pred * scale  # query-doc ä¹‹é—´çš„ç›¸ä¼¼åº¦
    y_pred = y_pred[:, None] - y_pred[None, :]  # query-docå¯¹ ä¹‹é—´çš„ç›¸ä¼¼åº¦çš„å·®å€¼ï¼Œy_pred[i, j]ä»£è¡¨ ç¬¬iå¯¹é¢„æµ‹åˆ†æ•° å’Œ ç¬¬jå¯¹é¢„æµ‹åˆ†æ•° ä¹‹é—´çš„å·®å€¼
    y_pred = K.reshape(y_pred - tf.cast((1 - y_true) * 1e12, tf.float32), [-1])
    # losså‡½æ•°çš„æœ€ç»ˆè®¡ç®—ä¸º reduce_logsumexp = log(âˆ‘(exp(x_i)))
    # 1e12å¯ä»¥çœ‹æˆâˆï¼Œå‰é¢åŠ ä¸ªå‡å·å˜æˆ-âˆï¼Œç”±äºexp(-âˆ)=0ï¼Œä¹Ÿå°±æ˜¯è¯´y_predä¸­ y_trueä¸º1æ‰€å¯¹åº”çš„åœ°æ–¹æ‰æ˜¯æœ€ç»ˆå¯¹lossæœ‰è´¡çŒ®çš„åœ°æ–¹ï¼Œå…¶ä½™åœ°æ–¹éƒ½æ˜¯-âˆï¼Œå¯¹åº”lossä¸º0
    # ä½†è¿™é‡Œæœ‰ä¸ªæ¯”è¾ƒéš¾ä»¥ç†è§£çš„åœ°æ–¹ï¼Œå› ä¸ºæˆ‘ä»¬æœŸæœ›æ­£æ ·æœ¬å¯¹çš„ç›¸ä¼¼åº¦ å¤§äº è´Ÿæ ·æœ¬å¯¹ï¼Œå¦‚æœy_true[i, j] = 1,åˆ™ä»£è¡¨ label_i < label_jï¼Œé‚£ä¹ˆæ­¤æ—¶å¦‚æœ pred_i < pred_j,åº”
    # è¯¥æ˜¯ç¬¦åˆé¢„æœŸçš„ï¼Œæ­¤æ—¶lossåº”è¯¥ä¸º0æ‰å¯¹ã€‚
    # ä½†æ˜¯ç”¨cosentè®¡ç®—å¹¶ä¸æ˜¯0ï¼Œè€Œæ˜¯exp(pred_i - pred_j)ï¼Œè™½ç„¶è¿™ä¸ªåˆ†æ•°æ¯”è¾ƒå°ï¼Œä½†æ˜¯ä»ç„¶æ˜¯æœ‰lossçš„ï¼Œå¹¶ä¸”ç”±äºscaleçš„åŠ å…¥ï¼Œlossè¿˜ä¼šè¢«è¿›ä¸€æ­¥æ”¾å¤§ã€‚
    # ä¸ºäº†ä¿®æ”¹è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥å°†y_pred ä¸ºè´Ÿæ•°çš„éƒ¨åˆ†ä¹Ÿç½®ä¸º-1e12ï¼Œè¿™æ ·å°±å¯ä»¥åŒæ ·å¿½ç•¥ æ»¡è¶³æœŸæœ›çš„éƒ¨åˆ† lossï¼Œå°†å…¶ç½®ä¸ºé›¶ï¼Œè¯¦ç»†å®ç°æ–¹æ¡ˆè§cosent_loss_v2
    y_pred = K.concatenate([[0], y_pred], axis=0)  # è¿™ä¸ªæ˜¯ä¸ºäº†å¯¹åº”å…¬å¼æœ€å‰é¢çš„+1ï¼Œä¿è¯losséƒ½æ˜¯å¤§äº0çš„
    return tf.reduce_logsumexp(y_pred, axis=None, keepdims=False)  # log(âˆ‘(exp(x_i)))


@tf.function
def cosent_loss(y_true, query, doc, scale=20):
    """cosent æ ¸å¿ƒå‡½æ•°
    """
    y_true = K.cast(y_true[:, None] < y_true[None, :], K.floatx())  # query-docå¯¹ label ä¸¤ä¸¤æ¯”è¾ƒï¼Œy_true[i, j]ä»£è¡¨ ç¬¬iå¯¹label æ˜¯å¦å°äº ç¬¬jå¯¹label
    y_pred = K.sum(query * doc, axis=1) * scale  # query-doc ä¹‹é—´çš„ç›¸ä¼¼åº¦
    y_pred = y_pred[:, None] - y_pred[None, :]  # query-docå¯¹ ä¹‹é—´çš„ç›¸ä¼¼åº¦çš„å·®å€¼ï¼Œy_pred[i, j]ä»£è¡¨ ç¬¬iå¯¹é¢„æµ‹åˆ†æ•° å’Œ ç¬¬jå¯¹é¢„æµ‹åˆ†æ•° ä¹‹é—´çš„å·®å€¼
    y_pred = K.reshape(y_pred - tf.cast((1 - y_true) * 1e12, tf.float32), [-1])
    # losså‡½æ•°çš„æœ€ç»ˆè®¡ç®—ä¸º reduce_logsumexp = log(âˆ‘(exp(x_i)))
    # 1e12å¯ä»¥çœ‹æˆâˆï¼Œå‰é¢åŠ ä¸ªå‡å·å˜æˆ-âˆï¼Œç”±äºexp(-âˆ)=0ï¼Œä¹Ÿå°±æ˜¯è¯´y_predä¸­ y_trueä¸º1æ‰€å¯¹åº”çš„åœ°æ–¹æ‰æ˜¯æœ€ç»ˆå¯¹lossæœ‰è´¡çŒ®çš„åœ°æ–¹ï¼Œå…¶ä½™åœ°æ–¹éƒ½æ˜¯-âˆï¼Œå¯¹åº”lossä¸º0
    # ä½†è¿™é‡Œæœ‰ä¸ªæ¯”è¾ƒéš¾ä»¥ç†è§£çš„åœ°æ–¹ï¼Œå› ä¸ºæˆ‘ä»¬æœŸæœ›æ­£æ ·æœ¬å¯¹çš„ç›¸ä¼¼åº¦ å¤§äº è´Ÿæ ·æœ¬å¯¹ï¼Œå¦‚æœy_true[i, j] = 1,åˆ™ä»£è¡¨ label_i < label_jï¼Œé‚£ä¹ˆæ­¤æ—¶å¦‚æœ pred_i < pred_j,åº”
    # è¯¥æ˜¯ç¬¦åˆé¢„æœŸçš„ï¼Œæ­¤æ—¶lossåº”è¯¥ä¸º0æ‰å¯¹ã€‚
    # ä½†æ˜¯ç”¨cosentè®¡ç®—å¹¶ä¸æ˜¯0ï¼Œè€Œæ˜¯exp(pred_i - pred_j)ï¼Œè™½ç„¶è¿™ä¸ªåˆ†æ•°æ¯”è¾ƒå°ï¼Œä½†æ˜¯ä»ç„¶æ˜¯æœ‰lossçš„ï¼Œå¹¶ä¸”ç”±äºscaleçš„åŠ å…¥ï¼Œlossè¿˜ä¼šè¢«è¿›ä¸€æ­¥æ”¾å¤§ã€‚
    # ä¸ºäº†ä¿®æ”¹è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥å°†y_pred ä¸ºè´Ÿæ•°çš„éƒ¨åˆ†ä¹Ÿç½®ä¸º-1e12ï¼Œè¿™æ ·å°±å¯ä»¥åŒæ ·å¿½ç•¥ æ»¡è¶³æœŸæœ›çš„éƒ¨åˆ† lossï¼Œå°†å…¶ç½®ä¸ºé›¶ï¼Œè¯¦ç»†å®ç°æ–¹æ¡ˆè§cosent_loss_v2
    y_pred = K.concatenate([[0], y_pred], axis=0)  # è¿™ä¸ªæ˜¯ä¸ºäº†å¯¹åº”å…¬å¼æœ€å‰é¢çš„+1
    return tf.reduce_logsumexp(y_pred, axis=None, keepdims=False)  # log(âˆ‘(exp(x_i)))


@tf.function
def cosent_loss_v2(y_true, query, doc, scale=20):
    """ç›¸æ¯”äºcosentï¼Œå°†è´Ÿæ•°éƒ¨åˆ†ä¹Ÿç½®ä¸º-1e12ï¼Œä½¿å…¶å¯¹æ•´ä½“lossæ— è´¡çŒ®
    """
    y_true = K.cast(y_true[:, None] < y_true[None, :], tf.float64)
    y_pred = K.sum(query * doc, axis=1) * scale
    y_pred = y_pred[:, None] - y_pred[None, :]
    y_pred = K.reshape(y_pred - (1 - y_true) * 1e12, [-1])
    y_pred = tf.where(y_pred > 0, y_pred, -1e12)  # æœ€æ ¸å¿ƒçš„æ”¹å˜ï¼Œå°†è´Ÿæ•°éƒ¨åˆ†å…¨éƒ¨ç½®ä¸º-1e12ï¼Œä½¿å…¶å¯¹æ•´ä½“lossæ— è´¡çŒ®
    y_pred = K.concatenate([[0], y_pred], axis=0)
    return tf.reduce_logsumexp(y_pred, axis=None, keepdims=False)


@tf.function
def aux_label_cosent_loss(y_true, aux_true, query, doc, scale=20, alpha: float = .5):
    """
    è¾…åŠ©æŒ‡æ ‡çš„cosentï¼Œè¯¥lossä¼šç”¨æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬æ¥åˆ†åˆ«å¯¹è¾…åŠ©labelåšcosentæœ€åæ±‚å’Œ
    æ¯”è¾ƒé€‚åˆçš„è¾…åŠ©æŒ‡æ ‡æœ‰ï¼š
        - å‡ºä»·bidï¼ˆä¹Ÿå¯ä»¥æ˜¯bidåˆ†ç®±åå†å¯¹æ¯”ï¼Œè¿™é‡Œè¦æ³¨æ„ï¼Œå¿…é¡»å¾—è®©bidæœ¬èº«æ˜¯å¯æ¯”çš„ï¼Œæ¯”å¦‚å¯ä»¥è®©å¤§å®¶éƒ½æ¢ç®—æˆocpc bidï¼Œè¶Šæ·±åº¦è½¬åŒ–bidè¶Šé«˜ï¼Œå› æ­¤éœ€è¦ç»Ÿä¸€è½¬åŒ–ä¸‹ï¼‰
        - ecpm = bid * ctr
        - å…¶å®ƒä¸šåŠ¡æŒ‡æ ‡
    å› æ­¤è¯¥lossåªè¦æ˜¯æƒ³è®©æŸäº›ä¸šåŠ¡æŒ‡æ ‡æ’åºé å‰çš„æ—¶å€™éƒ½å¯ä»¥ä½¿ç”¨
    :param alpha:
    :param y_true: 0/1 label
    :param aux_true: è¾…åŠ©label
    :param query: queryå‘é‡
    :param doc: docå‘é‡
    :param scale: ç¼©æ”¾å‚æ•°
    :param alpha: è´Ÿæ ·æœ¬è¾…åŠ©labelæƒé‡
    :return: losså€¼
    """
    pos_ind = tf.squeeze(tf.where(y_true == 1))  # è¿™é‡Œå…¶å®è€ƒè™‘äº†å…¨éƒ¨éƒ½ä¸º0çš„æƒ…å†µï¼Œlossè¿”å›ç›´æ¥æ˜¯0
    neg_ind = tf.squeeze(tf.where(y_true == 0))  # è¿™é‡Œå…¶å®è€ƒè™‘äº†å…¨éƒ¨éƒ½ä¸º0çš„æƒ…å†µï¼Œlossè¿”å›ç›´æ¥æ˜¯0
    pos_loss = cosent_loss_v2(tf.gather(aux_true, pos_ind), tf.gather(query, pos_ind), tf.gather(doc, pos_ind), scale)
    neg_loss = cosent_loss_v2(tf.gather(aux_true, neg_ind), tf.gather(query, neg_ind), tf.gather(doc, neg_ind), scale)
    return (1 - alpha) * pos_loss + alpha * neg_loss


@tf.function
def pos_aux_label_cosent_loss(y_true, aux_true, query, doc, scale=20):
    """
    è¾…åŠ©æŒ‡æ ‡çš„cosentï¼Œè¯¥lossä¼šè¿‡æ»¤æ‰æ ·æœ¬ä¸­çš„è´Ÿæ ·æœ¬ï¼Œä»…ç”¨æ­£æ ·æœ¬æ¥å¯¹è¾…åŠ©labelåšcosent
    æ¯”è¾ƒé€‚åˆçš„è¾…åŠ©æŒ‡æ ‡æœ‰ï¼š
        - å‡ºä»·bidï¼ˆä¹Ÿå¯ä»¥æ˜¯bidåˆ†ç®±åå†å¯¹æ¯”ï¼Œè¿™é‡Œè¦æ³¨æ„ï¼Œå¿…é¡»å¾—è®©bidæœ¬èº«æ˜¯å¯æ¯”çš„ï¼Œæ¯”å¦‚å¯ä»¥è®©å¤§å®¶éƒ½æ¢ç®—æˆocpc bidï¼Œè¶Šæ·±åº¦è½¬åŒ–bidè¶Šé«˜ï¼Œå› æ­¤éœ€è¦ç»Ÿä¸€è½¬åŒ–ä¸‹ï¼‰
        - ecpm = bid * ctr
        - å…¶å®ƒä¸šåŠ¡æŒ‡æ ‡
    å› æ­¤è¯¥lossåªè¦æ˜¯æƒ³è®©æŸäº›ä¸šåŠ¡æŒ‡æ ‡æ’åºé å‰çš„æ—¶å€™éƒ½å¯ä»¥ä½¿ç”¨
    :param y_true: 0/1 label
    :param aux_true: è¾…åŠ©label
    :param query: queryå‘é‡
    :param doc: docå‘é‡
    :param scale: ç¼©æ”¾å‚æ•°
    :return: losså€¼
    """
    pos_ind = tf.squeeze(tf.where(y_true == 1))  # è¿™é‡Œå…¶å®è€ƒè™‘äº†å…¨éƒ¨éƒ½ä¸º0çš„æƒ…å†µï¼Œlossè¿”å›ç›´æ¥æ˜¯0
    return cosent_loss_v2(tf.gather(aux_true, pos_ind), tf.gather(query, pos_ind), tf.gather(doc, pos_ind), scale)


@tf.function
def batch_neg_sample_ce_loss(y_true, query, doc):
    """
    batch å†…è´Ÿé‡‡æ ·äº¤å‰ç†µï¼Œè‡ªå®ç°ï¼Œç›¸å½“äºqueryæ˜¯logitsï¼Œdocæ˜¯labelï¼Œå³åˆ†ç±»queryï¼Œground-truthä¸ºdocï¼Œqueryå¯¹docçš„å¤šåˆ†ç±»äº¤å‰ç†µ
    y_true: æ ‡ç­¾/æ‰“åˆ† [2 * None, 1]
    y_pred: å¥å‘é‡ [2 * None, 768]
    scale: æ¸©åº¦å‚æ•°
    å®ç°batchå†…è´Ÿé‡‡æ ·ï¼Œå…¬å¼ä¸ºï¼š
    lossğ‘– = âˆ’(1/n) * Sigma(y_trueÂ·log(y_pred) + (1-y_true)Â·log(1-y_pred))
    """
    y_true = tf.linalg.diag(y_true)
    y_pred = tf.matmul(query, tf.transpose(doc))
    return tf.reduce_mean(K.categorical_crossentropy(y_true, y_pred) * tf.linalg.diag_part(y_true))


@tf.function
def batch_neg_sample_symmetrical_ce_loss(y_true, query, doc):
    """
    batch å†…è´Ÿé‡‡æ ·äº¤å‰ç†µï¼Œè‡ªå®ç°ï¼ŒåŒ…å«å¯¹ç§°éƒ¨åˆ†ï¼Œå¢åŠ äº†docå¯¹queryçš„å¤šåˆ†ç±»äº¤å‰ç†µ
    y_true: æ ‡ç­¾/æ‰“åˆ† [2 * None, 1]
    y_pred: å¥å‘é‡ [2 * None, 768]
    scale: æ¸©åº¦å‚æ•°
    å®ç°batchå†…è´Ÿé‡‡æ ·ï¼Œå…¬å¼ä¸ºï¼š
    """
    y_true = tf.linalg.diag(y_true)
    y_pred1 = tf.matmul(query, tf.transpose(doc))
    y_pred2 = tf.matmul(doc, tf.transpose(query))
    loss = 1/2 * (K.categorical_crossentropy(y_true, y_pred1) + K.categorical_crossentropy(y_true, y_pred2)) * tf.linalg.diag_part(y_true)
    return tf.reduce_mean(loss)


@tf.function
def batch_neg_sample_scaled_multi_class_ce_loss(y_true, query, doc, scale=20):
    """
    batch å†…è´Ÿé‡‡æ ·äº¤å‰ç†µ
    å¤ç°è‡ªè®ºæ–‡ï¼šQue2Search: https://zhuanlan.zhihu.com/p/415516966
    y_true: æ ‡ç­¾/æ‰“åˆ† [2 * None, 1], ä¸åŒäºè®ºæ–‡ä¸­çš„lossåªå…è®¸labelä¸º1ï¼Œè¿™é‡Œå…è®¸labelå¯ä»¥æœ‰0ä¹Ÿæœ‰1ï¼Œç›®çš„æ˜¯åŠ å…¥åŠ å…¥çƒ­é—¨ç‰©æ–™ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œè¿›è¡Œçƒ­åº¦é™æƒ
    y_pred: å¥å‘é‡ [2 * None, 768]
    scale: æ¸©åº¦å‚æ•°
    å®ç°batchå†…è´Ÿé‡‡æ ·ï¼Œå…¬å¼ä¸ºï¼š
        - lossğ‘– = âˆ’log(exp(ğ‘ Â·cos{ğ‘ğ‘–,ğ‘‘ğ‘–})/ Sigma(exp(ğ‘ Â·cos{ğ‘ğ‘–,ğ‘‘ğ‘—})))
    """
    y_true = tf.linalg.diag(y_true)
    y_pred = tf.matmul(query, tf.transpose(doc))
    num = tf.linalg.diag_part(tf.exp(scale * y_pred))  # åªå–å¯¹è§’çº¿ä¸Šçš„expå€¼
    den = tf.reduce_sum(tf.exp(scale * y_pred), axis=-1)
    loss = -K.log(num / den) * tf.linalg.diag_part(y_true)
    return tf.reduce_mean(loss)


@tf.function
def batch_neg_sample_symmetrical_scaled_multi_class_ce_loss(y_true, query, doc, scale=20):
    """
    å¤ç°è‡ªè®ºæ–‡ï¼šQue2Search: https://zhuanlan.zhihu.com/p/415516966
    batch å†…è´Ÿé‡‡æ ·äº¤å‰ç†µ
    y_true: æ ‡ç­¾/æ‰“åˆ† [2 * None, 1], ä¸åŒäºè®ºæ–‡ä¸­çš„lossåªå…è®¸labelä¸º1ï¼Œè¿™é‡Œå…è®¸labelå¯ä»¥æœ‰0ä¹Ÿæœ‰1ï¼Œç›®çš„æ˜¯åŠ å…¥åŠ å…¥çƒ­é—¨ç‰©æ–™ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œè¿›è¡Œçƒ­åº¦é™æƒ
    y_pred: å¥å‘é‡ [2 * None, 768]
    scale: æ¸©åº¦å‚æ•°
    å®ç°batchå†…è´Ÿé‡‡æ ·ï¼Œå…¬å¼ä¸ºï¼š
    lossğ‘– = âˆ’1/2*[log(exp(ğ‘ Â·cos{ğ‘ğ‘–,ğ‘‘ğ‘–})/ Sigma(exp(ğ‘ Â·cos{ğ‘ğ‘–,ğ‘‘ğ‘—}))) + log(exp(ğ‘ Â·cos{ğ‘ğ‘–,ğ‘‘ğ‘–})/ Sigma(exp(ğ‘ Â·cos{ğ‘ğ‘—,ğ‘‘ğ‘–})))]
    """
    y_true = tf.linalg.diag(y_true)
    y_pred = scale * tf.matmul(query, tf.transpose(doc))
    # ç›¸å½“äºå¯¹queryåšåˆ†ç±»ä»»åŠ¡ï¼Œç±»åˆ«æ˜¯doc
    num1 = tf.linalg.diag_part(tf.exp(scale * y_pred))  # åªå–å¯¹è§’çº¿ä¸Šçš„expå€¼
    den1 = tf.reduce_sum(tf.exp(scale * y_pred), axis=-1)
    # ç›¸å½“äºå¯¹docåšåˆ†ç±»ä»»åŠ¡ï¼Œç±»åˆ«æ˜¯query
    num2 = tf.linalg.diag_part(tf.exp(scale * y_pred))  # åªå–å¯¹è§’çº¿ä¸Šçš„expå€¼
    den2 = tf.reduce_sum(tf.exp(scale * y_pred), axis=-1)
    # æœ€åå°†ä¸¤éƒ¨åˆ†åŠ å’Œï¼Œå¾ˆæ˜æ˜¾ï¼Œä¸å…‰ç…§é¡¾äº†queryçš„åˆ†ç±»å‡†ç¡®åº¦ï¼Œè¿˜ç…§é¡¾åˆ°äº†docä¾§çš„åˆ†ç±»å‡†ç¡®åº¦ï¼Œåœ¨docä¸ºä¸»çš„åœºæ™¯æ›´æœ‰æ•ˆã€‚
    loss = -1/2 * (K.log(num1 / den1) + K.log(num2 / den2)) * tf.linalg.diag_part(y_true)
    return tf.reduce_mean(loss)


@tf.function
def batch_neg_sample_margin_rank_loss(y_true, query, doc, margin=0.1):
    """
    è‡ªå®ç°batchå†…è´Ÿé‡‡æ ·çš„ltr lossï¼Œæ¯ä¸ªqueryé™¤äº†æ­£æ ·æœ¬ä»¥å¤–å…¶ä»–docå‡ä¸ºè´Ÿæ ·æœ¬
    y_true: æ ‡ç­¾/æ‰“åˆ† [2 * None, 1]
    y_pred: å¥å‘é‡ [2 * None, 768]
    margin: é—´éš”å‚æ•°ï¼Œä¸€èˆ¬å–0.1 ~ 0.2æœ€ä½³
    lossğ‘– = Sigma_j(ğ‘šğ‘ğ‘¥(0, âˆ’[ğ‘ğ‘œğ‘ (ğ‘ğ‘–,ğ‘‘ğ‘–) âˆ’ ğ‘ğ‘œğ‘ (ğ‘ğ‘–,ğ‘‘ğ‘›ğ‘ğ‘–_j)] + ğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘›))
    """
    y_pred = tf.matmul(query, tf.transpose(doc))
    y_sub = -(tf.linalg.diag_part(y_pred)[:, None] - y_pred) + margin

    loss = tf.clip_by_value(y_sub, 0, 1e14) * y_true
    return tf.reduce_sum(loss)


@tf.function
def batch_hard_neg_sample_margin_rank_loss(y_true, query, doc, margin=0.1):
    """
    å¤ç°è‡ªè®ºæ–‡ï¼šQue2Search: https://zhuanlan.zhihu.com/p/415516966
    batch å†…è´Ÿé‡‡æ ·äº¤å‰ç†µï¼Œå¹¶ä¸”è·å–é™¤äº†æ­£æ ·æœ¬å¤–ç›¸ä¼¼åº¦æœ€é«˜çš„ä¸€ä¸ªæ ·æœ¬ä¸ºå›°éš¾è´Ÿæ ·æœ¬
    æ³¨æ„ï¼šè¯¥Lossä¸èƒ½åœ¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹ä¸Šä½¿ç”¨ï¼å› ä¸ºéœ€è¦ç”¨ç›¸ä¼¼åº¦æ¥è¯„ä¼°å‡ºå›°éš¾æ ·æœ¬ï¼Œå› æ­¤éœ€è¦æ¨¡å‹é¦–å…ˆæ”¶æ•›ï¼Œå…¶æ¬¡å†è¿›è¡Œå›°éš¾è®­ç»ƒ
    y_true: æ ‡ç­¾/æ‰“åˆ† [2 * None, 1]
    y_pred: å¥å‘é‡ [2 * None, 768]
    margin: é—´éš”å‚æ•°ï¼Œä¸€èˆ¬å–0.1 ~ 0.2æœ€ä½³
    """
    y_pred = tf.matmul(query, tf.transpose(doc))
    y_pos_cos = tf.linalg.diag_part(y_pred)

    y_neg_pred = y_pred - tf.linalg.diag(tf.linalg.diag_part(y_pred))  # å°†y_predçš„å¯¹è§’çº¿éƒ½ç½®ä¸º0
    y_neg_cos = K.max(y_neg_pred, axis=-1)
    y_sub = -(y_pos_cos - y_neg_cos) + margin

    loss = tf.clip_by_value(y_sub, 0, 1e14) * y_true
    return tf.reduce_sum(loss)
